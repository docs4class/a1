[["index.html", "Data Analytics One - Class Materials and Lessons Chapter 1 Introduction 1.1 About R 1.2 What Good is Data Science?", " Data Analytics One - Class Materials and Lessons Authored and Edited by: Dr. Turner and Seth Cooper 2021-12-16 Chapter 1 Introduction This is a book written in Markdown which contains all the materials and lessons for data analytics one. If you miss a day, want to review something we covered in class, or for any reason want to look for a worksheet, this is where you can go. Each chapter contains a different topic we will cover during the semester. Some larger topics are split into two chapters to make accessing the materials a little more intuitive. This book is updated automatically with any changes made to the documents during the semester, so if at any point you are told there was a change in the assignment, you can come here to get the updated version. Also, this book has benefited greatly from lots of free, readily availabe resources posted on the web and we leverage these extensively. I would encourage you to review these resources in your analytics journey. Some that we specifically use with great frequency are these (and I say loud THANK YOU to the authors!): R for Data Science An Introduction to Statistical Learning with Applications in R R: A self-learn tutorial Data Science in a Box stackoverflow, for example 1.1 About R R is a software language for carrying out complicated (and simple) statistical analyses. It includes routines for data summary and exploration, graphical presentation and data modelling. The aim of this document is to provide you with a basic fluency in the language. It is suggested that you work through this document at the computer, having started an R session. Type in all of the commands that are printed, and check that you understand how they operate. Then try the simple exercises at the end of each section. When you work in R you create objects that are stored in the current workspace (sometimes called image). Each object created remains in the image unless you explicitly delete it. At the end of the session the workspace will be lost unless you save it. You can save the workspace at any time by clicking on the disc icon at the top of the control panel. Commands written in R are saved in memory throughout the session. You can scroll back to previous commands typed by using the up arrow key (and down to scroll back again). You can also copy and paste using standard windows editor techniques (for example, using the copy and paste dialog buttons). If at any point you want to save the transcript of your session, click on File and then Save History, which will enable you to save a copy of the commands you have used for later use. As an alternative you might copy and paste commands manually into a notepad editor or something similar. 1.2 What Good is Data Science? There are a variety of different applications for R. Yes, the more obvious ones would be things such as machine learning, artificial intelligence, and data mining. However, the possibilities with this program are honestly limitless. Take a look at this rather funny example of data analytics being used by retail giant Target to predict whether women were pregnant and how it put one teenager in a rather uncomfortable situation. Click for Target Pregnancy Model Story What other applications are there? Well, are you interested in sports? Did you know that almost all professional athletic teams have dedicated teams of data scientists whose job it is to watch for patterns and collect data from the games in order to help the coaches make better calls and more effective plays? Click Data Analytics in the NBA Story Presbyterian College has a very high number of STEM majors. Specifically, biology is one of the most declared majors on campus. Data science is used by biologists and many other scientists around the world to help create data and compelling visualizations in order to convey their findings. Check out this interesting story about data science being used in the world of biology. Click for Computational Biology Story As you can no doubt see, it is more than likely safe to say that data science will one day be a major factor in almost every field some day. Data already surrounds us and is used by companies all over the world for a variety of tasks. By creating a foundation of these skills for yourself, regardless of whether your job title contains the words data science, you will be an asset to your company. Simply having the ability to understand and interpret data is one of the most sought after skills in the corporate sphere today. "],["r-basics.html", "Chapter 2 R basics and workflows 2.1 Basics of working with R at the command line and RStudio goodies 2.2 Workspace and working directory 2.3 Exercises", " Chapter 2 R basics and workflows 2.1 Basics of working with R at the command line and RStudio goodies Launch RStudio/R. You will first intall R and then. RStudio. Installing R Installing RStudio Customizing RStduio RStudio Quick keys Notice the default panes: Console (entire left) Environment/History (tabbed in upper right) Files/Plots/Packages/Help (tabbed in lower right) FYI: you can change the default location of the panes, among many other things: [Customizing RStudio][rstudio-customizing]. Go into the Console, where we interact with the live R process. You can make an object by assigning a value or statement to a letter or string. We use &lt;- to assign objects meaning. Create and inspect the following object: x &lt;- 3 * 4 x ## [1] 12 All R statements where you create objects  assignments  have this form: objectName &lt;- value and in my head I hear, e.g., x gets 12. You will make lots of assignments and the operator &lt;- is a pain to type. Dont be lazy and use =, although it would work, because it will just sow confusion later. Instead, utilize RStudios keyboard shortcut: Alt + - (the minus sign). Notice that RStudio automatically surrounds &lt;- with spaces, which demonstrates a useful code formatting practice. Code is miserable to read on a good day. Give your eyes a break and use spaces. RStudio offers many handy [keyboard shortcuts][rstudio-key-shortcuts]. Also, Alt+Shift+K brings up a keyboard shortcut reference card. Object names cannot start with a digit and cannot contain certain other characters such as a comma or a space. You will be wise to adopt a [convention for demarcating words][wiki-snake-case] in names, but note that best practice is to choose ONE convention and stay true to it throughout your code. i_use_snake_case other.people.use.periods evenOthersUseCamelCase Make another assignment: this_is_a_really_long_name &lt;- 2.5 To inspect this, try out RStudios completion facility: type the first few characters, press TAB, add characters until you disambiguate, then press return. Make another assignment: turner_rocks &lt;- 2 ^ 3 When making assignments, it is best practice to keep the names brief, yet descriptive. For instance, while the name this_is_a_really_long_name is accurate, so is long_name and this is much more intuitive and easy to read/type over and over. Lets try to inspect: turnerrocks ## Error in eval(expr, envir, enclos): object &#39;turnerrocks&#39; not found Turner_rocks ## Error in eval(expr, envir, enclos): object &#39;Turner_rocks&#39; not found turner_rocks ## [1] 8 Implicit contract with the computer / scripting language: Computer will do tedious computation for you. In return, you will be completely precise in your instructions. Typos matter. Case matters. Get better at typing. R has a mind-blowing collection of built-in functions that are accessed like so: functionName(arg1 = val1, arg2 = val2, and so on) Lets try using seq() which makes regular sequences of numbers and, while were at it, demo more helpful features of RStudio. Type se and hit TAB. A pop up shows you possible completions. Specify seq() by typing more to disambiguate or using the up/down arrows to select. Notice the floating tool-tip-type help that pops up, reminding you of a functions arguments. If you want even more help, press F1 as directed to get the full documentation in the help tab of the lower right pane. Now open the parentheses and notice the automatic addition of the closing parenthesis and the placement of cursor in the middle. Type the arguments 1, 10 and hit return. RStudio also exits the parenthetical expression for you. IDEs are great. seq(1, 10) ## [1] 1 2 3 4 5 6 7 8 9 10 The above also demonstrates something about how R resolves function arguments. You can always specify in name = value form. But if you do not, R attempts to resolve by position. So above, it is assumed that we want a sequence from = 1 that goes to = 10. Since we didnt specify step size, the default value of by in the function definition is used, which ends up being 1 in this case. For functions I call often, I might use this resolve by position for the first argument or maybe the first two. After that, I always use name = value. Make this assignment and notice similar help with quotation marks. yo &lt;- &quot;hello world&quot; If you just make an assignment, you dont get to see the value, so then youre tempted to immediately inspect. y &lt;- seq(1, 10) y ## [1] 1 2 3 4 5 6 7 8 9 10 This common action can be shortened by surrounding the assignment with parentheses, which causes assignment and print to screen to happen. It is best practice to always attempt to print your assignments after creating them. This will help leviate the issue of searching 200+ lines of code for that one error causing argument. (y &lt;- seq(1, 10)) ## [1] 1 2 3 4 5 6 7 8 9 10 Not all functions have (or require) arguments: date() ## [1] &quot;Thu Dec 16 09:44:21 2021&quot; Now look at your workspace  in the upper right pane. The workspace is where user-defined objects accumulate. You can also get a listing of these objects with commands: objects() ## [1] &quot;this_is_a_really_long_name&quot; &quot;turner_rocks&quot; ## [3] &quot;x&quot; &quot;y&quot; ## [5] &quot;yo&quot; ls() ## [1] &quot;this_is_a_really_long_name&quot; &quot;turner_rocks&quot; ## [3] &quot;x&quot; &quot;y&quot; ## [5] &quot;yo&quot; If you want to remove the object named y, you can do this: rm(y) To remove everything: rm(list = ls()) or click the broom in RStudios Environment pane. 2.2 Workspace and working directory One day you will need to quit R, go do something else and return to your analysis later (this is a very happy day). One day you will have multiple analyses going that use R and you want to keep them separate (a not so happy day). One day you will need to bring data from the outside world into R and send numerical results and figures from R back out into the world (the happiest of days). To handle these real life situations, you need to make two decisions: What about your analysis is real, i.e. will you save it as your lasting record of what happened? Where does your analysis live? 2.2.1 Workspace, .RData As a beginning R user, its OK to consider your workspace real. Very soon, I urge you to evolve to the next level, where you consider your saved R scripts as real. (In either case, of course the input data is very much real and requires preservation!) With the input data and the R code you used, you can reproduce everything. You can make your analysis fancier. You can get to the bottom of puzzling results and discover and fix bugs in your code. You can reuse the code to conduct similar analyses in new projects. You can remake a figure with different aspect ratio or save is as TIFF instead of PDF. You are ready to take questions. You are ready for the future. If you regard your workspace as real (saving and reloading all the time), if you need to redo analysis  youre going to either redo a lot of typing (making mistakes all the way) or will have to mine your R history for the commands you used. Rather than [becoming an expert on managing the R history][rstudio-command-history], a better use of your time and psychic energy is to keep your good R code in a script for future reuse. Because it can be useful sometimes, note the commands youve recently run appear in the History pane. But you dont have to choose right now and the two strategies are not incompatible. Lets demo the save / reload the workspace approach. Upon quitting R, you have to decide if you want to save your workspace, for potential restoration the next time you launch R. Depending on your set up, R or your IDE, e.g. RStudio, will probably prompt you to make this decision. Quit R/RStudio, either from the menu, using a keyboard shortcut, or by typing q() in the Console. Youll get a prompt like this: Save workspace image to ~/.Rdata? Note where the workspace image is to be saved and then click Save. Using your favorite method, visit the directory where image was saved and verify there is a file named .RData. You will also see a file .Rhistory, holding the commands submitted in your recent session. Restart RStudio. In the Console you will see a line like this: [Workspace loaded from ~/.RData] indicating that your workspace has been restored. Look in the Workspace pane and youll see the same objects as before. In the History tab of the same pane, you should also see your command history. Youre back in business. This way of starting and stopping analytical work will not serve you well for long but its a start. 2.2.2 Working directory Any process running on your computer has a notion of its working directory. In R, this is where R will look, by default, for files you ask it to load. It also where, by default, any files you write to disk will go. Chances are your current working directory is the directory we inspected above, i.e. the one where RStudio wanted to save the workspace. You can explicitly check your working directory with: getwd() It is also displayed at the top of the RStudio console. As a beginning R user, its OK let your home directory or any other weird directory on your computer be Rs working directory. Very soon, I urge you to evolve to the next level, where you organize your analytical projects into directories and, when working on project A, set Rs working directory to the associated directory. Although I do not recommend it, in case youre curious, you can set Rs working directory at the command line like so: setwd(&quot;~/myCoolProject&quot;) Although I do not recommend it, you can also use RStudios Files pane to navigate to a directory and then set it as working directory from the menu: Session &gt; Set Working Directory &gt; To Files Pane Location. (Youll see even more options there). Or within the Files pane, choose More and Set As Working Directory. But theres a better way. A way that also puts you on the path to managing your R work like an expert. 2.3 Exercises Create an object called cool_object and assign it the number 100. Create a new object called big_brain and multiply the object from question one by 15. Print both objects. Use base R functions to return todays date and print it. Create a sequence of numbers counting from 10 to 100 by 2. Identify your working directory. What is it? Change it to where you want it. Save the R script that answers questions 1 through 5 above. Save it; clean and close Rstudio; reopen your script and run it. Make sense? "],["r-vs.-excel.html", "Chapter 3 R vs. Excel 3.1 Both are useful 3.2 Differences Between R and Excel 3.3 Ease of Use &amp; Learning the Software 3.4 Replicating Analysis 3.5 Visualization 3.6 Packages 3.7 Careers 3.8 Summary  Using R and Excel", " Chapter 3 R vs. Excel 3.1 Both are useful Data analytics are increasingly important components of decision-making in any business. Whether youre a part of a marketing team that needs to generate visuals to highlight industry trends, or youre looking to generate financial statements, you will need an analytics program to help you develop your reports and effectively communicate your findings. Both R and Excel are excellent data analytics tools, but they each have distinct functionality. Please make sure you can explain the distict funtions of both R and Excel! YOU WILL NEED TO KNOW THIS! Excel is a well-known software program included in the Microsoft Office Suite. Used to create spreadsheets, execute calculations, produce charts, and perform statistical analysis, Excel is used by many professionals across a variety of industries. PCs BADM 299 prepares you well for using Excel. R is a free, open-source programming language and software environment thats frequently used in big data analysis and statistical computing. R has many advanced functions and capabilities. 3.2 Differences Between R and Excel When choosing between R and Excel, its important to understand how either software can get you the results you need. Here are some key differences between R and Excel to help you decide which makes the most sense to use. 3.3 Ease of Use &amp; Learning the Software Most people have likely already learned at least a few basic tips in Microsoft Excel. Thats one substantial benefit of using Excelthe initial learning curve is quite minimal, and most analysis can be done via point-and-click on the top panel. Once a user imports their data into the program, its not very hard to make basic graphs and charts. R is a programming language, however, meaning the initial learning curve is steeper. It will take most at least a few weeks to familiarize themselves with the interface and master the various functions. Luckily, using R can quickly become second-nature with practice. 3.4 Replicating Analysis R, while less user-friendly with a more intimidating user interface, has the capability to reproduce analyses repeatedly and with very different datasets. This can be incredibly helpful for large projects with multiple data sets, as youll keep everything consistent and clean, without having to rewrite the script each time. Since Excels user interface is point-and-click, youll need to rely on memory and repetition frequently. You cannot import codes and scripts as you would with R, so youll have to reinvent the wheel to perform the same analysis across different data sets. This is not detrimental if you are doing basic statistics, but it may become time-consuming with more complicated analyses. For example, lets say you have thoroughly analyzed the analytics of 1 football season. How could R (vs Excel) help you quickly analyze a new seasons data? 3.5 Visualization When deciding between R and Excel, ask yourself, How detailed do my visualizations need to be in order to achieve my goal(s)? In Excel, for example, you can quickly highlight a group of cells and make a simple chart for PowerPoint. If you need a more comprehensive graph, however, R may be your best bet. R can produce incredibly attractive, detailed visuals that can help stakeholders understand your findings. It all comes down to what you need your graphics to do. If youre just looking to cobble together a quick-and-dirty presentation to visualize data for your coworkers, then making simple straightforward charts in Excel will suffice. For those planning to publish large amounts of complicated data to various stakeholders, spending the time in R to create impressive interactive visual representations will likely be worth your while. For example, heres and example of a pretty easy visualization in R that would be challenging to do (and update) in Excel. 3.6 Packages In R, the fundamental unit of shareable code is the package. A package bundles together code, data, documentation, and tests, and is easy to share with others. As of June 2019, there were over 14,000 packages available on the Comprehensive R Archive Network, or CRAN, the public clearing house for R packages. This huge variety of packages is one of the reasons that R is so successful: the chances are that someone has already solved a problem that youre working on, and you can benefit from their work by downloading their package. But packages are useful even if you never share your code. As Hilary Parker says in her introduction to packages: Seriously, it doesnt have to be about sharing your code (although that is an added benefit!). It is about saving yourself time. Organising code in a package makes your life easier because packages come with conventions. For example, you put R code in R/, you put tests in tests/ and you put data in data/. These conventions are helpful because: They save you time  you dont need to think about the best way to organise a project, you can just follow a template. Standardized conventions lead to standardized tools  if you buy into Rs package conventions, you get many tools for free. We will chat more about packages, but for fun check out the links below 3.7 Careers Aptitude with Excel and R are incredibly valuable competencies that are in-demand across a variety of industries. Countless jobs are looking for applicants with at least some Excel experience (pivot tables look really good on a resumé), but R has a higher earning potential and is more in-demand than Excel. R is one of the most popular programming languages and is an industry-standard for data analytics and data science. If you want to enter either field, theres a good chance youll have a competitive advantage by knowing R. Entry-level jobs for those focusing on R also tend to make a high salary, frequently starting off earning more than $75,000. Countless job listings also require Excel competency. From administrative assistants, marketers, academics, and more, everyone is expected to use Excel to some degree, whereas 10 to 15 years ago it was optional. Having a good background in Excel is still attractive on a resumé and will help to land a career with a high earning potential, but there are not many jobs looking for Excel skills alone. 3.8 Summary  Using R and Excel R and Excel are beneficial in different ways. Excel starts off easier to learn and is frequently cited as the go-to program for reporting, thanks to its speed and efficiency. R is designed to handle larger data sets, to be reproducible, and to create more detailed visualizations. Its not a question of choosing between R and Excel, but deciding which program to use for different needs. "],["objects-and-arithmetic.html", "Chapter 4 Objects and Arithmetic 4.1 Introduction 4.2 Basic Functions 4.3 Statistics and Summaries 4.4 Exercises", " Chapter 4 Objects and Arithmetic 4.1 Introduction R stores information and operates on objects. The simplest objects are scalars, vectors and matrices. But there are many others: lists and dataframes for example. In advanced use of R it can also be useful to define new types of object, specific for particular application. We will stick with just the most commonly used objects here. An important feature of R is that it will do different things on different types of objects. For example, type: 4+6 ## [1] 10 So, R does scalar arithmetic returning the scalar value 10. (In actual fact, R returns a vector of length 1 - hence the [1] denoting first element of the vector. We can assign objects values for subsequent use. For example: x&lt;-6 y&lt;-4 z&lt;-x+y would do the same calculation as above, storing the result in an object called z. We can look at the contents of the object by simply typing its name: z ## [1] 10 Storing things such as calculations as objects is extremely useful, especially in longer scripts. Mainly because you will likely call the same equation multiple times and if you need to revise it in any way you only need to change the initial assignment rather than every line. 4.2 Basic Functions At any time we can list the objects which we have created: ls() ## [1] &quot;g&quot; &quot;mpg&quot; &quot;mpg_select&quot; &quot;x&quot; &quot;y&quot; ## [6] &quot;z&quot; Notice that ls is actually an object itself. Typing ls would result in a display of the contents of this object, in this case, the commands of the function. The use of parentheses, ls(), ensures that the function is executed and its result - in this case, a list of the objects in the directory - displayed. More commonly a function will operate on an object, for example: sqrt(16) ## [1] 4 calculates the square root of 16. Objects can be removed from the current workspace with the rm function: rm(x,y) for example. There are many standard functions available in R, and it is also possible to create new ones. Vectors can be created in R in a number of ways. We can describe all of the elements: z&lt;-c(5,9,1,0) Note the use of the function c to concatenate or âglue togetherâ individual elements. This function can be used much more widely, for example x&lt;-c(5,9) y&lt;-c(1,0) z&lt;-c(x,y) would lead to the same result by gluing together two vectors to create a single vector. Sequences can be generated as follows: x&lt;-1:10 while more general sequences can be generated using the seq command. For example: seq(1,9,by=2) ## [1] 1 3 5 7 9 seq(8,20,length=6) ## [1] 8.0 10.4 12.8 15.2 17.6 20.0 These examples illustrate that many functions in R have optional arguments, in this case, either the step length or the total length of the sequence (it doesnât make sense to use both). If you leave out both of these options, R will make its own default choice, in this case assuming a step length of 1. So, for example, seq(8,20,length=6) ## [1] 8.0 10.4 12.8 15.2 17.6 20.0 x&lt;-seq(1,10) x ## [1] 1 2 3 4 5 6 7 8 9 10 also generates a vector of integers from 1 to 10. At this point itâs worth mentioning the help facility. If you donât know how to use a function, or donât know what the options or default values are, type help(functionname) where functionname is the name of the function you are interested in. This will usually help and will often include examples to make things even clearer. Another useful function for building vectors is the rep command for repeating things. For example: rep(0,100) ## [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [38] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 rep(1:3,6) ## [1] 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 rep(1:3,c(6,6,6)) ## [1] 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3 which we could also simplify cleverly as: rep(1:3,rep(6,3)) ## [1] 1 1 1 1 1 1 2 2 2 2 2 2 3 3 3 3 3 3 As explained above, R will often adapt to the objects it is asked to work on. For example: x&lt;-c(6,8,9) y&lt;-c(1,2,4) x+y ## [1] 7 10 13 and x*y ## [1] 6 16 36 showing that R uses componentwise arithmetic on vectors. R will also try to make sense if objects are mixed. For example: x&lt;-c(6,8,9) x+2 ## [1] 8 10 11 though care should be taken to make sure that R is doing what you would like it to in these circumstances. Two particularly useful functions worth remembering are length which returns the length of a vector (i.e. the number of elements it contains) and sum which calculates the sum of the elements of a vector. 4.3 Statistics and Summaries One of the most useful functions of R is its ability to perform statistical analysis on large pieces of data. Later in this book we will cover how this analysis can be used to build complex models and test their accuracy. For now, the focus will be on how to perform basic statistical analysis and the definitions of the more basic terms. 4.3.1 Statistical Analysis Youve undoubtedly have heard the terms mean, median, standard deviation and variance. However, if asked to define these terms and provide examples of their usefulness, what would you say? This section is going to answer the first part of that question. Mean is a pretty straight forward concept for most. Commonly referred to as the average, you find this number by adding all the numbers in your data set together and then divide by the total number of points you used. This is easily done on a calculator if you are working with less then 20 digits, however this is almost never the case in data science. Often, especially with R, you will be dealing with data sets with hundreds, thousands, or maybe even hundreds of thousands of data points. Fortunately, R takes the pain away from this process and offers a very simple function that will do this for you. Start by creating an object that contains a list of numbers, and then simply use the mean function to calculate the average of your variable. a &lt;- c(3.8,4,3.1,2.1,12.6,17,8.43,11,2,3,9,5,3,0.5) mean(a) ## [1] 6.037857 The median of a data set is data point that fall in the middle of all the other points when they are ordered from lowest to highest. Again, something easily found even without a calculator if you have small data sets, however humans can miscount and some data sets are just too massive for us to do on our own. R never makes these counting mistakes and by using a simple function you save yourself hours of mundane counting. Start the same way you found mean by creating an object with various numbers and then simply use the median function. b &lt;- c(3.8,4,3.1,2.1,12.6,17,8.43,11,2,3,9,5,3,0.5) median(b) ## [1] 3.9 Many people have heard of standard deviation, but not many can provide an accurate definition. Standard deviation is the measure of variance (see next paragraph) between numbers in a data set and that data sets mean. Typically a lower standard deviation is what you want to see as this proves there is little variance in your data set and that typically means a higher correlation. If you wanted to find this by hand you would have to find the square root of the variance between each point and the mean. This is easy if you have all the numbers you need, but that is almost never the case and thus you would have to calculate all that variance by hand and that is too much work. Why take all those extra steps when R can do it for you? The sd() function does all the work without any hassle, all you have to do is identify the object you want it to find the standard deviation of. d &lt;- c(3.8,4,3.1,2.1,12.6,17,8.43,11,2,3,9,5,3,0.5) sd(d) ## [1] 4.821066 Finally, we can cover variance. Variance is the measure of distance between two numbers. This statistic is often used to measure how spread out your data is and can be used to determine your models accuracy. Typically, a higher variance means your model is inaccurate. So, when building models and reviewing your summary statistics, you want your variance to be as low as possible. There is a var() function that will find the variance of a variable for you, however typically you will create a confusion matrix (discussed in a later section) that will help you determine the variance, and thus accuracy of your model. 4.3.2 Anscombes Quartet You may be asking now, why bother visualizing data if I have all these numbers that will tell me what I need to know about my data? You are correct in saying that statistical data is very useful, and in many cases essential, however visualization is equally as important. Anscombes Quartet is a statistical phenomenon where four sets of data have very similar statistical properties, but very are completely different when graphed. Lets take a look at the data: ## x1 x2 x3 x4 y1 y2 y3 y4 ## 1 10 10 10 8 8.04 9.14 7.46 6.58 ## 2 8 8 8 8 6.95 8.14 6.77 5.76 ## 3 13 13 13 8 7.58 8.74 12.74 7.71 ## 4 9 9 9 8 8.81 8.77 7.11 8.84 ## 5 11 11 11 8 8.33 9.26 7.81 8.47 ## 6 14 14 14 8 9.96 8.10 8.84 7.04 ## 7 6 6 6 8 7.24 6.13 6.08 5.25 ## 8 4 4 4 19 4.26 3.10 5.39 12.50 ## 9 12 12 12 8 10.84 9.13 8.15 5.56 ## 10 7 7 7 8 4.82 7.26 6.42 7.91 ## 11 5 5 5 8 5.68 4.74 5.73 6.89 ## x1 x2 x3 x4 y1 y2 ## nobs 11.000000 11.000000 11.000000 11.000000 11.000000 11.000000 ## NAs 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 ## Minimum 4.000000 4.000000 4.000000 8.000000 4.260000 3.100000 ## Maximum 14.000000 14.000000 14.000000 19.000000 10.840000 9.260000 ## 1. Quartile 6.500000 6.500000 6.500000 8.000000 6.315000 6.695000 ## 3. Quartile 11.500000 11.500000 11.500000 8.000000 8.570000 8.950000 ## Mean 9.000000 9.000000 9.000000 9.000000 7.500909 7.500909 ## Median 9.000000 9.000000 9.000000 8.000000 7.580000 8.140000 ## Sum 99.000000 99.000000 99.000000 99.000000 82.510000 82.510000 ## SE Mean 1.000000 1.000000 1.000000 1.000000 0.612541 0.612568 ## LCL Mean 6.771861 6.771861 6.771861 6.771861 6.136083 6.136024 ## UCL Mean 11.228139 11.228139 11.228139 11.228139 8.865735 8.865795 ## Variance 11.000000 11.000000 11.000000 11.000000 4.127269 4.127629 ## Stdev 3.316625 3.316625 3.316625 3.316625 2.031568 2.031657 ## Skewness 0.000000 0.000000 0.000000 2.466911 -0.048374 -0.978693 ## Kurtosis -1.528926 -1.528926 -1.528926 4.520661 -1.199123 -0.514319 ## y3 y4 ## nobs 11.000000 11.000000 ## NAs 0.000000 0.000000 ## Minimum 5.390000 5.250000 ## Maximum 12.740000 12.500000 ## 1. Quartile 6.250000 6.170000 ## 3. Quartile 7.980000 8.190000 ## Mean 7.500000 7.500909 ## Median 7.110000 7.040000 ## Sum 82.500000 82.510000 ## SE Mean 0.612196 0.612242 ## LCL Mean 6.135943 6.136748 ## UCL Mean 8.864057 8.865070 ## Variance 4.122620 4.123249 ## Stdev 2.030424 2.030579 ## Skewness 1.380120 1.120774 ## Kurtosis 1.240044 0.628751 As you can see from the table, the summary statistics for the four tables look very similar, however lets graph these and see what kind of visualizations we get. Pretty rad right? So yes, statistical data is vital, however it should not be the only thing you look at, sometimes a visualization can help you understand the data more! Later in this book, and in the upper level data analytics courses, we will cover visualizations more and how they can be useful. 4.4 Exercises Define x&lt;-c(4,2,6) y&lt;-c(1,0,-1) Decide what the result will be of the following: length(x) sum(x) sum(x^2) x+y x*y x-2 x^2 Use R to check your answers. Decide what the following sequences are and use R to check your answers: 7:11 seq(2,9) seq(4,10,by=2) seq(3,30,length=10) seq(6,-4,by=-2) Determine what the result will be of the following R expressions, and then use R to check if you are right: rep(2,4) rep(c(1,2),4) rep(c(1,2),c(4,4)) rep(1:4,4) rep(1:4,rep(3,4)) Use the rep function to define simply the following vectors in R. 6,6,6,6,6,6 5,8,5,8,5,8,5,8 5,5,5,5,8,8,8,8 "],["summaries-and-subscripting.html", "Chapter 5 Summaries and Subscripting 5.1 Introduction 5.2 Exercises (Summaries and Subscripting)", " Chapter 5 Summaries and Subscripting 5.1 Introduction Lets suppose weve collected some data from an experiment and stored them in an object x: x&lt;-c(7.5,8.2,3.1,5.6,8.2,9.3,6.5,7.0,9.3,1.2,14.5,6.2) Some simple summary statistics of these data can be produced: mean(x) ## [1] 7.216667 var(x) ## [1] 11.00879 sd(x) ## [1] 3.317949 summary(x) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.200 6.050 7.250 7.217 8.475 14.500 which should all be self explanatory. It may be, however, that we subsequently learn that the first 6 data points correspond to measurements made on one machine, and the second six on another machine. This might lead us to want to summarize the two sets of data separately, so we would need to extract from x the two relevant subvectors. This is achieved by subscripting: x[1:6] ## [1] 7.5 8.2 3.1 5.6 8.2 9.3 x[7:12] ## [1] 6.5 7.0 9.3 1.2 14.5 6.2 summary(x[1:6]) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 3.100 6.075 7.850 6.983 8.200 9.300 summary(x[7:12]) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.200 6.275 6.750 7.450 8.725 14.500 Other subsets can be created in the obvious way. For example: x[c(2,4,9)] ## [1] 8.2 5.6 9.3 Negative integers can be used to exclude particular elements. For example x[-(1:6)] ## [1] 6.5 7.0 9.3 1.2 14.5 6.2 has the same effect as x[7:12] ## [1] 6.5 7.0 9.3 1.2 14.5 6.2 5.2 Exercises (Summaries and Subscripting) If x&lt;- c(5,9,2,3,4,6,7,0,8,12,2,9) decide what each of the following is and use R to check your answers: x[2] x[2:4] x[c(2,3,6)] x[c(1:5,10:12)] x[-(10:12)] The data y&lt;-c(33,44,29,16,25,45,33,19,54,22,21,49,11,24,56) contain sales of milk in gallons for 5 days in three different shops (the frst 3 values are for shops 1,2 and 3 on Monday, etc.) Produce a statistical summary of the sales for each day of the week and also for each shop. "],["matrices.html", "Chapter 6 Matrices 6.1 CBind and RBind 6.2 Matrix Function 6.3 Exercises", " Chapter 6 Matrices 6.1 CBind and RBind Matrices can be created in R in a variety of ways. Perhaps the simplest is to create the columns (just a couple of objects)and then glue them together with the command cbind. For example, x&lt;-c(5,7,9) y&lt;-c(6,3,4) z&lt;-cbind(x,y) z ## x y ## [1,] 5 6 ## [2,] 7 3 ## [3,] 9 4 The dimension of a matrix can be checked with the dim command: dim(z) ## [1] 3 2 [1] 3 2 i.e., three rows and two columns. There is a similar command, rbind, for building matrices by gluing rows together. The functions cbind and rbind can also be applied to matrices themselves (provided the dimensions match) to form larger matrices. For example, rbind(z,z) ## x y ## [1,] 5 6 ## [2,] 7 3 ## [3,] 9 4 ## [4,] 5 6 ## [5,] 7 3 ## [6,] 9 4 6.1.1 Review Questions Create a matrix made up of two columns showing the GPAs and number of hours studied by seven students. Recreate the following matrix in R: ## x y ## [1,] 5 3.4 ## [2,] 7 4.0 ## [3,] 2 2.5 ## [4,] 3 3.2 ## [5,] 8 2.8 ## [6,] 4 3.1 ## [7,] 2 3.6 Using the appropriate function, combine the two matrices you created above. 6.2 Matrix Function Matrices can also be built by explicit construction via the function matrix. For example, z&lt;-matrix(c(5,7,9,6,3,4),nrow=3) results in a matrix z identical to z above. Notice that the dimension of the matrix is determined by the size of the vector and the requirement that the number of rows is 3, as specified by the argument nrow=3. As an alternative we could have specified the number of columns with the argument ncol=2 (obviously, it is unnecessary to give both). Notice that the matrix is flled up column-wise. If instead you wish to fill up row-wise, add the option byrow=T. For example, z&lt;-matrix(c(5,7,9,6,3,4),nr=3,byrow=T) z ## [,1] [,2] ## [1,] 5 7 ## [2,] 9 6 ## [3,] 3 4 Notice that the argument nrow has been abbreviated to nr. Such abbreviations are always possible for function arguments provided it induces no ambiguity - if in doubt always use the full argument name. As usual, R will try to interpret operations on matrices in a natural way. For example, with z as above, and y&lt;-matrix(c(1,3,0,9,5,-1),nrow=3,byrow=T) y ## [,1] [,2] ## [1,] 1 3 ## [2,] 0 9 ## [3,] 5 -1 we obtain y+z ## [,1] [,2] ## [1,] 6 10 ## [2,] 9 15 ## [3,] 8 3 and y*z ## [,1] [,2] ## [1,] 5 21 ## [2,] 0 54 ## [3,] 15 -4 Other useful functions on matrices are to transpose a matrix: z ## [,1] [,2] ## [1,] 5 7 ## [2,] 9 6 ## [3,] 3 4 t(z) ## [,1] [,2] [,3] ## [1,] 5 9 3 ## [2,] 7 6 4 As with vectors it is useful to be able to extract sub-components of matrices. In this case, wemay wish to pick out individual elements, rows or columns. As before, the [ ] notation is used to subscript. The following examples should make things clear: z[1,1] ## [1] 5 z[c(2,3),2] ## [1] 6 4 z[,2] ## [1] 7 6 4 z[1:2,] ## [,1] [,2] ## [1,] 5 7 ## [2,] 9 6 So, in particular, it is necessary to specify which rows and columns are required, whilst omitting the integer for either dimension implies that every element in that dimension is selected. 6.3 Exercises Create this matrix in R ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 7 8 11 -5 ## [2,] 3 8 6 3 -9 ## [3,] 0 11 14 14 14 Create in R these matrices: x ## [,1] [,2] ## [1,] 1 7 ## [2,] 8 11 ## [3,] 5 9 y ## [,1] [,2] ## [1,] 6 8 ## [2,] 2 1 ## [3,] 1 -7 Calculate the following and check your answers in R: 2*x x*x t(y) ## [,1] [,2] ## [1,] 2 14 ## [2,] 16 22 ## [3,] 10 18 ## [,1] [,2] ## [1,] 1 49 ## [2,] 64 121 ## [3,] 25 81 ## [,1] [,2] [,3] ## [1,] 6 2 1 ## [2,] 8 1 -7 With x and y as above, calculate the effect of the following subscript operations and check your answers in R. x[1,] x[2,] x[,2] y[1,2] y[,2:3] "],["playing-with-data-using-mtcars.html", "Chapter 7 Playing With Data (Using mtcars) 7.1 Practicing with mtcars data set 7.2 Excerises for you:", " Chapter 7 Playing With Data (Using mtcars) 7.1 Practicing with mtcars data set This demonstration is based on the datasset mtcars. Read in mtcars data(mtcars) View first few rows and last few rows of mtcars dataframe using functions head() and tail() head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 tail(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.7 0 1 5 2 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.9 1 1 5 2 ## Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.5 0 1 5 4 ## Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.5 0 1 5 6 ## Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.6 0 1 5 8 ## Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.6 1 1 4 2 Some info about mtcars dataframe using function colnames(), rownames(), and dim() colnames(mtcars) ## [1] &quot;mpg&quot; &quot;cyl&quot; &quot;disp&quot; &quot;hp&quot; &quot;drat&quot; &quot;wt&quot; &quot;qsec&quot; &quot;vs&quot; &quot;am&quot; &quot;gear&quot; ## [11] &quot;carb&quot; rownames(mtcars) ## [1] &quot;Mazda RX4&quot; &quot;Mazda RX4 Wag&quot; &quot;Datsun 710&quot; ## [4] &quot;Hornet 4 Drive&quot; &quot;Hornet Sportabout&quot; &quot;Valiant&quot; ## [7] &quot;Duster 360&quot; &quot;Merc 240D&quot; &quot;Merc 230&quot; ## [10] &quot;Merc 280&quot; &quot;Merc 280C&quot; &quot;Merc 450SE&quot; ## [13] &quot;Merc 450SL&quot; &quot;Merc 450SLC&quot; &quot;Cadillac Fleetwood&quot; ## [16] &quot;Lincoln Continental&quot; &quot;Chrysler Imperial&quot; &quot;Fiat 128&quot; ## [19] &quot;Honda Civic&quot; &quot;Toyota Corolla&quot; &quot;Toyota Corona&quot; ## [22] &quot;Dodge Challenger&quot; &quot;AMC Javelin&quot; &quot;Camaro Z28&quot; ## [25] &quot;Pontiac Firebird&quot; &quot;Fiat X1-9&quot; &quot;Porsche 914-2&quot; ## [28] &quot;Lotus Europa&quot; &quot;Ford Pantera L&quot; &quot;Ferrari Dino&quot; ## [31] &quot;Maserati Bora&quot; &quot;Volvo 142E&quot; dim(mtcars) ## [1] 32 11 7.2 Excerises for you: Find the minimum and maximum value of mpg Find the mean and standard deviation of data variable mpg What variable has a 3rd quartile value of 180.0? Create and explain what this means Create and explain what this means ## mpg cyl disp hp drat wt ## mpg 1.0000000 -0.8521620 -0.8475514 -0.7761684 0.68117191 -0.8676594 ## cyl -0.8521620 1.0000000 0.9020329 0.8324475 -0.69993811 0.7824958 ## disp -0.8475514 0.9020329 1.0000000 0.7909486 -0.71021393 0.8879799 ## hp -0.7761684 0.8324475 0.7909486 1.0000000 -0.44875912 0.6587479 ## drat 0.6811719 -0.6999381 -0.7102139 -0.4487591 1.00000000 -0.7124406 ## wt -0.8676594 0.7824958 0.8879799 0.6587479 -0.71244065 1.0000000 ## qsec 0.4186840 -0.5912421 -0.4336979 -0.7082234 0.09120476 -0.1747159 ## vs 0.6640389 -0.8108118 -0.7104159 -0.7230967 0.44027846 -0.5549157 ## am 0.5998324 -0.5226070 -0.5912270 -0.2432043 0.71271113 -0.6924953 ## gear 0.4802848 -0.4926866 -0.5555692 -0.1257043 0.69961013 -0.5832870 ## carb -0.5509251 0.5269883 0.3949769 0.7498125 -0.09078980 0.4276059 ## qsec vs am gear carb ## mpg 0.41868403 0.6640389 0.59983243 0.4802848 -0.55092507 ## cyl -0.59124207 -0.8108118 -0.52260705 -0.4926866 0.52698829 ## disp -0.43369788 -0.7104159 -0.59122704 -0.5555692 0.39497686 ## hp -0.70822339 -0.7230967 -0.24320426 -0.1257043 0.74981247 ## drat 0.09120476 0.4402785 0.71271113 0.6996101 -0.09078980 ## wt -0.17471588 -0.5549157 -0.69249526 -0.5832870 0.42760594 ## qsec 1.00000000 0.7445354 -0.22986086 -0.2126822 -0.65624923 ## vs 0.74453544 1.0000000 0.16834512 0.2060233 -0.56960714 ## am -0.22986086 0.1683451 1.00000000 0.7940588 0.05753435 ## gear -0.21268223 0.2060233 0.79405876 1.0000000 0.27407284 ## carb -0.65624923 -0.5696071 0.05753435 0.2740728 1.00000000 Create a variable called efficiency which is mpg divided by weight. Which car has the max efficiency and what is this value? Which variable in this dataset has the greatest standard deviation? How many cars have 3 gears? How many cars get more than 17 mpg? "],["dplyr.html", "Chapter 8 DPLYR 8.1 Introduction 8.2 Single table verbs 8.3 The pipe 8.4 Loading dplyr and the nycflights13 dataset 8.5 Choosing columns: select, rename 8.6 Choosing rows: filter, between, slice, sample_n, top_n, distinct 8.7 Adding new variables: mutate, transmute, add_rownames 8.8 Grouping and counting: summarise, tally, count, group_size, n_groups, ungroup 8.9 Creating data frames: data_frame 8.10 Joining (merging) tables: left_join, right_join, inner_join, full_join, semi_join, anti_join 8.11 Viewing more output: print, View 8.12 Resources 8.13 Data School", " Chapter 8 DPLYR 8.1 Introduction For more help PLEASE check out Introduction to dplyr introducing the key functionality of the dplyr package. Your life is about to change. For the better, even. 8.2 Single table verbs dplyr aims to provide a function for each basic verb of data manipulation. These verbs can be organised into three categories based on the component of the dataset that they work with: Rows: filter() chooses rows based on column values. slice() chooses rows based on location. arrange() changes the order of the rows. Columns: select() changes whether or not a column is included. rename() changes the name of columns. mutate() changes the values of columns and creates new columns. relocate() changes the order of the columns. Groups of rows: summarise() collapses a group into a single row. Its not that useful until we learn the group_by() verb below. 8.3 The pipe All of the dplyr functions take a data frame (or tibble) as the first argument. Rather than forcing the user to either save intermediate objects or nest functions, dplyr provides the %&gt;% operator from magrittr. x %&gt;% f(y) turns into f(x, y) so the result from one step is then piped into the next step. You can use the pipe to rewrite multiple operations that you can read left-to-right, top-to-bottom (reading the pipe operator as then). 8.4 Loading dplyr and the nycflights13 dataset # load packages suppressMessages(library(dplyr)) library(nycflights13) # print the flights dataset from nycflights13 head(flights) ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 819 ## 2 2013 1 1 533 529 4 850 830 ## 3 2013 1 1 542 540 2 923 850 ## 4 2013 1 1 544 545 -1 1004 1022 ## 5 2013 1 1 554 600 -6 812 837 ## 6 2013 1 1 554 558 -4 740 728 ## # ... with 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, ## # tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, ## # hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 8.5 Choosing columns: select, rename # besides just using select() to pick columns... flights %&gt;% select(carrier, flight) ## # A tibble: 336,776 x 2 ## carrier flight ## &lt;chr&gt; &lt;int&gt; ## 1 UA 1545 ## 2 UA 1714 ## 3 AA 1141 ## 4 B6 725 ## 5 DL 461 ## 6 UA 1696 ## 7 B6 507 ## 8 EV 5708 ## 9 B6 79 ## 10 AA 301 ## # ... with 336,766 more rows # ...you can use the minus sign to hide columns flights %&gt;% select(-month, -day) ## # A tibble: 336,776 x 17 ## year dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2013 517 515 2 830 819 11 ## 2 2013 533 529 4 850 830 20 ## 3 2013 542 540 2 923 850 33 ## 4 2013 544 545 -1 1004 1022 -18 ## 5 2013 554 600 -6 812 837 -25 ## 6 2013 554 558 -4 740 728 12 ## 7 2013 555 600 -5 913 854 19 ## 8 2013 557 600 -3 709 723 -14 ## 9 2013 557 600 -3 838 846 -8 ## 10 2013 558 600 -2 753 745 8 ## # ... with 336,766 more rows, and 10 more variables: carrier &lt;chr&gt;, ## # flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, ## # distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # hide a range of columns flights %&gt;% select(-(dep_time:arr_delay)) # hide any column with a matching name flights %&gt;% select(-contains(&quot;time&quot;)) # pick columns using a character vector of column names cols &lt;- c(&quot;carrier&quot;, &quot;flight&quot;, &quot;tailnum&quot;) flights %&gt;% select(one_of(cols)) ## # A tibble: 336,776 x 3 ## carrier flight tailnum ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 UA 1545 N14228 ## 2 UA 1714 N24211 ## 3 AA 1141 N619AA ## 4 B6 725 N804JB ## 5 DL 461 N668DN ## 6 UA 1696 N39463 ## 7 B6 507 N516JB ## 8 EV 5708 N829AS ## 9 B6 79 N593JB ## 10 AA 301 N3ALAA ## # ... with 336,766 more rows # select() can be used to rename columns, though all columns not mentioned are dropped flights %&gt;% select(tail = tailnum) ## # A tibble: 336,776 x 1 ## tail ## &lt;chr&gt; ## 1 N14228 ## 2 N24211 ## 3 N619AA ## 4 N804JB ## 5 N668DN ## 6 N39463 ## 7 N516JB ## 8 N829AS ## 9 N593JB ## 10 N3ALAA ## # ... with 336,766 more rows # rename() does the same thing, except all columns not mentioned are kept flights %&gt;% rename(tail = tailnum) ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 819 ## 2 2013 1 1 533 529 4 850 830 ## 3 2013 1 1 542 540 2 923 850 ## 4 2013 1 1 544 545 -1 1004 1022 ## 5 2013 1 1 554 600 -6 812 837 ## 6 2013 1 1 554 558 -4 740 728 ## 7 2013 1 1 555 600 -5 913 854 ## 8 2013 1 1 557 600 -3 709 723 ## 9 2013 1 1 557 600 -3 838 846 ## 10 2013 1 1 558 600 -2 753 745 ## # ... with 336,766 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tail &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 8.6 Choosing rows: filter, between, slice, sample_n, top_n, distinct # filter() supports the use of multiple conditions flights %&gt;% filter(dep_time &gt;= 600, dep_time &lt;= 605) ## # A tibble: 2,460 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 600 600 0 851 858 ## 2 2013 1 1 600 600 0 837 825 ## 3 2013 1 1 601 600 1 844 850 ## 4 2013 1 1 602 610 -8 812 820 ## 5 2013 1 1 602 605 -3 821 805 ## 6 2013 1 2 600 600 0 814 749 ## 7 2013 1 2 600 605 -5 751 818 ## 8 2013 1 2 600 600 0 819 815 ## 9 2013 1 2 600 600 0 846 846 ## 10 2013 1 2 600 600 0 737 725 ## # ... with 2,450 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # between() is a concise alternative for determing if numeric values fall in a range flights %&gt;% filter(between(dep_time, 600, 605)) # side note: is.na() can also be useful when filtering flights %&gt;% filter(!is.na(dep_time)) # slice() filters rows by position flights %&gt;% slice(1000:1005) ## # A tibble: 6 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 2 809 810 -1 950 948 ## 2 2013 1 2 810 800 10 1008 1014 ## 3 2013 1 2 811 815 -4 1100 1056 ## 4 2013 1 2 811 815 -4 1126 1131 ## 5 2013 1 2 811 820 -9 944 955 ## 6 2013 1 2 815 815 0 1109 1128 ## # ... with 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, ## # tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, ## # hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # keep the first three rows within each group flights %&gt;% group_by(month, day) %&gt;% slice(1:3) ## # A tibble: 1,095 x 19 ## # Groups: month, day [365] ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 819 ## 2 2013 1 1 533 529 4 850 830 ## 3 2013 1 1 542 540 2 923 850 ## 4 2013 1 2 42 2359 43 518 442 ## 5 2013 1 2 126 2250 156 233 2359 ## 6 2013 1 2 458 500 -2 703 650 ## 7 2013 1 3 32 2359 33 504 442 ## 8 2013 1 3 50 2145 185 203 2311 ## 9 2013 1 3 235 2359 156 700 437 ## 10 2013 1 4 25 2359 26 505 442 ## # ... with 1,085 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # sample three rows from each group flights %&gt;% group_by(month, day) %&gt;% sample_n(3) ## # A tibble: 1,095 x 19 ## # Groups: month, day [365] ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 1521 1515 6 1830 1823 ## 2 2013 1 1 1910 1910 0 2126 2107 ## 3 2013 1 1 1315 1317 -2 1413 1423 ## 4 2013 1 2 1720 1730 -10 1959 1959 ## 5 2013 1 2 1753 1700 53 2052 2014 ## 6 2013 1 2 808 815 -7 1020 1016 ## 7 2013 1 3 1643 1640 3 2001 1955 ## 8 2013 1 3 1156 1158 -2 1522 1502 ## 9 2013 1 3 1024 1030 -6 1210 1215 ## 10 2013 1 4 1733 1710 23 1835 1820 ## # ... with 1,085 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # keep three rows from each group with the top dep_delay flights %&gt;% group_by(month, day) %&gt;% top_n(3, dep_delay) ## # A tibble: 1,108 x 19 ## # Groups: month, day [365] ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 848 1835 853 1001 1950 ## 2 2013 1 1 1815 1325 290 2120 1542 ## 3 2013 1 1 2343 1724 379 314 1938 ## 4 2013 1 2 1412 838 334 1710 1147 ## 5 2013 1 2 1607 1030 337 2003 1355 ## 6 2013 1 2 2131 1512 379 2340 1741 ## 7 2013 1 3 2008 1540 268 2339 1909 ## 8 2013 1 3 2012 1600 252 2314 1857 ## 9 2013 1 3 2056 1605 291 2239 1754 ## 10 2013 1 4 2058 1730 208 2 2110 ## # ... with 1,098 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # also sort by dep_delay within each group flights %&gt;% group_by(month, day) %&gt;% top_n(3, dep_delay) %&gt;% arrange(desc(dep_delay)) ## # A tibble: 1,108 x 19 ## # Groups: month, day [365] ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 9 641 900 1301 1242 1530 ## 2 2013 6 15 1432 1935 1137 1607 2120 ## 3 2013 1 10 1121 1635 1126 1239 1810 ## 4 2013 9 20 1139 1845 1014 1457 2210 ## 5 2013 7 22 845 1600 1005 1044 1815 ## 6 2013 4 10 1100 1900 960 1342 2211 ## 7 2013 3 17 2321 810 911 135 1020 ## 8 2013 6 27 959 1900 899 1236 2226 ## 9 2013 7 22 2257 759 898 121 1026 ## 10 2013 12 5 756 1700 896 1058 2020 ## # ... with 1,098 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # unique rows can be identified using unique() from base R flights %&gt;% select(origin, dest) %&gt;% unique() ## # A tibble: 224 x 2 ## origin dest ## &lt;chr&gt; &lt;chr&gt; ## 1 EWR IAH ## 2 LGA IAH ## 3 JFK MIA ## 4 JFK BQN ## 5 LGA ATL ## 6 EWR ORD ## 7 EWR FLL ## 8 LGA IAD ## 9 JFK MCO ## 10 LGA ORD ## # ... with 214 more rows # dplyr provides an alternative that is more &quot;efficient&quot; flights %&gt;% select(origin, dest) %&gt;% distinct() # side note: when chaining, you don&#39;t have to include the parentheses if there are no arguments flights %&gt;% select(origin, dest) %&gt;% distinct 8.7 Adding new variables: mutate, transmute, add_rownames # mutate() creates a new variable (and keeps all existing variables) flights %&gt;% mutate(speed = distance/air_time*60) ## # A tibble: 336,776 x 20 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 819 ## 2 2013 1 1 533 529 4 850 830 ## 3 2013 1 1 542 540 2 923 850 ## 4 2013 1 1 544 545 -1 1004 1022 ## 5 2013 1 1 554 600 -6 812 837 ## 6 2013 1 1 554 558 -4 740 728 ## 7 2013 1 1 555 600 -5 913 854 ## 8 2013 1 1 557 600 -3 709 723 ## 9 2013 1 1 557 600 -3 838 846 ## 10 2013 1 1 558 600 -2 753 745 ## # ... with 336,766 more rows, and 12 more variables: arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;, ## # speed &lt;dbl&gt; # transmute() only keeps the new variables flights %&gt;% transmute(speed = distance/air_time*60) ## # A tibble: 336,776 x 1 ## speed ## &lt;dbl&gt; ## 1 370. ## 2 374. ## 3 408. ## 4 517. ## 5 394. ## 6 288. ## 7 404. ## 8 259. ## 9 405. ## 10 319. ## # ... with 336,766 more rows # example data frame with row names mtcars %&gt;% head() ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 # add_rownames() turns row names into an explicit variable mtcars %&gt;% add_rownames(&quot;model&quot;) %&gt;% head() ## Warning: `add_rownames()` was deprecated in dplyr 1.0.0. ## Please use `tibble::rownames_to_column()` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. ## # A tibble: 6 x 12 ## model mpg cyl disp hp drat wt qsec vs am gear carb ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Mazda RX4 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 Mazda RX4 W~ 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 Datsun 710 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 Hornet 4 Dr~ 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 ## 5 Hornet Spor~ 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 6 Valiant 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 # side note: dplyr no longer prints row names (ever) for local data frames mtcars %&gt;% tbl_df() ## Warning: `tbl_df()` was deprecated in dplyr 1.0.0. ## Please use `tibble::as_tibble()` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. ## # A tibble: 32 x 11 ## mpg cyl disp hp drat wt qsec vs am gear carb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 ## 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 ## # ... with 22 more rows 8.8 Grouping and counting: summarise, tally, count, group_size, n_groups, ungroup # summarise() can be used to count the number of rows in each group flights %&gt;% group_by(month) %&gt;% summarise(cnt = n()) ## # A tibble: 12 x 2 ## month cnt ## &lt;int&gt; &lt;int&gt; ## 1 1 27004 ## 2 2 24951 ## 3 3 28834 ## 4 4 28330 ## 5 5 28796 ## 6 6 28243 ## 7 7 29425 ## 8 8 29327 ## 9 9 27574 ## 10 10 28889 ## 11 11 27268 ## 12 12 28135 # tally() and count() can do this more concisely flights %&gt;% group_by(month) %&gt;% tally() flights %&gt;% count(month) # you can sort by the count flights %&gt;% group_by(month) %&gt;% summarise(cnt = n()) %&gt;% arrange(desc(cnt)) ## # A tibble: 12 x 2 ## month cnt ## &lt;int&gt; &lt;int&gt; ## 1 7 29425 ## 2 8 29327 ## 3 10 28889 ## 4 3 28834 ## 5 5 28796 ## 6 4 28330 ## 7 6 28243 ## 8 12 28135 ## 9 9 27574 ## 10 11 27268 ## 11 1 27004 ## 12 2 24951 # tally() and count() have a sort parameter for this purpose flights %&gt;% group_by(month) %&gt;% tally(sort=TRUE) flights %&gt;% count(month, sort=TRUE) # you can sum over a specific variable instead of simply counting rows flights %&gt;% group_by(month) %&gt;% summarise(dist = sum(distance)) ## # A tibble: 12 x 2 ## month dist ## &lt;int&gt; &lt;dbl&gt; ## 1 1 27188805 ## 2 2 24975509 ## 3 3 29179636 ## 4 4 29427294 ## 5 5 29974128 ## 6 6 29856388 ## 7 7 31149199 ## 8 8 31149334 ## 9 9 28711426 ## 10 10 30012086 ## 11 11 28639718 ## 12 12 29954084 # tally() and count() have a wt parameter for this purpose flights %&gt;% group_by(month) %&gt;% tally(wt = distance) flights %&gt;% count(month, wt = distance) # group_size() returns the counts as a vector flights %&gt;% group_by(month) %&gt;% group_size() ## [1] 27004 24951 28834 28330 28796 28243 29425 29327 27574 28889 27268 28135 # n_groups() simply reports the number of groups flights %&gt;% group_by(month) %&gt;% n_groups() ## [1] 12 # group by two variables, summarise, arrange (output is possibly confusing) flights %&gt;% group_by(month, day) %&gt;% summarise(cnt = n()) %&gt;% arrange(desc(cnt)) %&gt;% print(n = 40) ## `summarise()` has grouped output by &#39;month&#39;. You can override using the `.groups` argument. ## # A tibble: 365 x 3 ## # Groups: month [12] ## month day cnt ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 11 27 1014 ## 2 7 11 1006 ## 3 7 8 1004 ## 4 7 10 1004 ## 5 12 2 1004 ## 6 7 18 1003 ## 7 7 25 1003 ## 8 7 12 1002 ## 9 7 9 1001 ## 10 7 17 1001 ## 11 7 31 1001 ## 12 8 7 1001 ## 13 8 8 1001 ## 14 8 12 1001 ## 15 7 22 1000 ## 16 7 24 1000 ## 17 8 1 1000 ## 18 8 5 1000 ## 19 8 15 1000 ## 20 11 21 1000 ## 21 7 15 999 ## 22 7 19 999 ## 23 7 26 999 ## 24 7 29 999 ## 25 8 2 999 ## 26 8 9 999 ## 27 11 22 999 ## 28 8 16 998 ## 29 7 23 997 ## 30 7 30 997 ## 31 8 14 997 ## 32 7 16 996 ## 33 8 6 996 ## 34 8 19 996 ## 35 9 13 996 ## 36 9 26 996 ## 37 9 27 996 ## 38 4 15 995 ## 39 6 20 995 ## 40 6 26 995 ## # ... with 325 more rows # ungroup() before arranging to arrange across all groups flights %&gt;% group_by(month, day) %&gt;% summarise(cnt = n()) %&gt;% ungroup() %&gt;% arrange(desc(cnt)) ## `summarise()` has grouped output by &#39;month&#39;. You can override using the `.groups` argument. ## # A tibble: 365 x 3 ## month day cnt ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 11 27 1014 ## 2 7 11 1006 ## 3 7 8 1004 ## 4 7 10 1004 ## 5 12 2 1004 ## 6 7 18 1003 ## 7 7 25 1003 ## 8 7 12 1002 ## 9 7 9 1001 ## 10 7 17 1001 ## # ... with 355 more rows 8.9 Creating data frames: data_frame data_frame() is a better way than data.frame() for creating data frames. Benefits of data_frame(): You can use previously defined columns to compute new columns. It never coerces column types. It never munges column names. It never adds row names. It only recycles length 1 input. It returns a local data frame (a tbl_df). # data_frame() example data_frame(a = 1:6, b = a*2, c = &#39;string&#39;, &#39;d+e&#39; = 1) %&gt;% glimpse() ## Warning: `data_frame()` was deprecated in tibble 1.1.0. ## Please use `tibble()` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. ## Rows: 6 ## Columns: 4 ## $ a &lt;int&gt; 1, 2, 3, 4, 5, 6 ## $ b &lt;dbl&gt; 2, 4, 6, 8, 10, 12 ## $ c &lt;chr&gt; &quot;string&quot;, &quot;string&quot;, &quot;string&quot;, &quot;string&quot;, &quot;string&quot;, &quot;string&quot; ## $ `d+e` &lt;dbl&gt; 1, 1, 1, 1, 1, 1 # data.frame() example data.frame(a = 1:6, c = &#39;string&#39;, &#39;d+e&#39; = 1) %&gt;% glimpse() ## Rows: 6 ## Columns: 3 ## $ a &lt;int&gt; 1, 2, 3, 4, 5, 6 ## $ c &lt;chr&gt; &quot;string&quot;, &quot;string&quot;, &quot;string&quot;, &quot;string&quot;, &quot;string&quot;, &quot;string&quot; ## $ d.e &lt;dbl&gt; 1, 1, 1, 1, 1, 1 8.10 Joining (merging) tables: left_join, right_join, inner_join, full_join, semi_join, anti_join # create two simple data frames (a &lt;- data_frame(color = c(&quot;green&quot;,&quot;yellow&quot;,&quot;red&quot;), num = 1:3)) ## # A tibble: 3 x 2 ## color num ## &lt;chr&gt; &lt;int&gt; ## 1 green 1 ## 2 yellow 2 ## 3 red 3 (b &lt;- data_frame(color = c(&quot;green&quot;,&quot;yellow&quot;,&quot;pink&quot;), size = c(&quot;S&quot;,&quot;M&quot;,&quot;L&quot;))) ## # A tibble: 3 x 2 ## color size ## &lt;chr&gt; &lt;chr&gt; ## 1 green S ## 2 yellow M ## 3 pink L # only include observations found in both &quot;a&quot; and &quot;b&quot; (automatically joins on variables that appear in both tables) inner_join(a, b) ## Joining, by = &quot;color&quot; ## # A tibble: 2 x 3 ## color num size ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 green 1 S ## 2 yellow 2 M # include observations found in either &quot;a&quot; or &quot;b&quot; full_join(a, b) ## Joining, by = &quot;color&quot; ## # A tibble: 4 x 3 ## color num size ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 green 1 S ## 2 yellow 2 M ## 3 red 3 &lt;NA&gt; ## 4 pink NA L # include all observations found in &quot;a&quot; left_join(a, b) ## Joining, by = &quot;color&quot; ## # A tibble: 3 x 3 ## color num size ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 green 1 S ## 2 yellow 2 M ## 3 red 3 &lt;NA&gt; # include all observations found in &quot;b&quot; right_join(a, b) ## Joining, by = &quot;color&quot; ## # A tibble: 3 x 3 ## color num size ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 green 1 S ## 2 yellow 2 M ## 3 pink NA L # right_join(a, b) is identical to left_join(b, a) except for column ordering left_join(b, a) ## Joining, by = &quot;color&quot; ## # A tibble: 3 x 3 ## color size num ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 green S 1 ## 2 yellow M 2 ## 3 pink L NA # filter &quot;a&quot; to only show observations that match &quot;b&quot; semi_join(a, b) ## Joining, by = &quot;color&quot; ## # A tibble: 2 x 2 ## color num ## &lt;chr&gt; &lt;int&gt; ## 1 green 1 ## 2 yellow 2 # filter &quot;a&quot; to only show observations that don&#39;t match &quot;b&quot; anti_join(a, b) ## Joining, by = &quot;color&quot; ## # A tibble: 1 x 2 ## color num ## &lt;chr&gt; &lt;int&gt; ## 1 red 3 # sometimes matching variables don&#39;t have identical names b &lt;- b %&gt;% rename(col = color) # specify that the join should occur by matching &quot;color&quot; in &quot;a&quot; with &quot;col&quot; in &quot;b&quot; inner_join(a, b, by=c(&quot;color&quot; = &quot;col&quot;)) ## # A tibble: 2 x 3 ## color num size ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 green 1 S ## 2 yellow 2 M 8.11 Viewing more output: print, View # specify that you want to see more rows flights %&gt;% print(n = 15) ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 819 ## 2 2013 1 1 533 529 4 850 830 ## 3 2013 1 1 542 540 2 923 850 ## 4 2013 1 1 544 545 -1 1004 1022 ## 5 2013 1 1 554 600 -6 812 837 ## 6 2013 1 1 554 558 -4 740 728 ## 7 2013 1 1 555 600 -5 913 854 ## 8 2013 1 1 557 600 -3 709 723 ## 9 2013 1 1 557 600 -3 838 846 ## 10 2013 1 1 558 600 -2 753 745 ## 11 2013 1 1 558 600 -2 849 851 ## 12 2013 1 1 558 600 -2 853 856 ## 13 2013 1 1 558 600 -2 924 917 ## 14 2013 1 1 558 600 -2 923 937 ## 15 2013 1 1 559 600 -1 941 910 ## # ... with 336,761 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; # specify that you want to see ALL rows (don&#39;t run this!) flights %&gt;% print(n = Inf) # specify that you want to see all columns flights %&gt;% print(width = Inf) ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 819 ## 2 2013 1 1 533 529 4 850 830 ## 3 2013 1 1 542 540 2 923 850 ## 4 2013 1 1 544 545 -1 1004 1022 ## 5 2013 1 1 554 600 -6 812 837 ## 6 2013 1 1 554 558 -4 740 728 ## 7 2013 1 1 555 600 -5 913 854 ## 8 2013 1 1 557 600 -3 709 723 ## 9 2013 1 1 557 600 -3 838 846 ## 10 2013 1 1 558 600 -2 753 745 ## arr_delay carrier flight tailnum origin dest air_time distance hour minute ## &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 11 UA 1545 N14228 EWR IAH 227 1400 5 15 ## 2 20 UA 1714 N24211 LGA IAH 227 1416 5 29 ## 3 33 AA 1141 N619AA JFK MIA 160 1089 5 40 ## 4 -18 B6 725 N804JB JFK BQN 183 1576 5 45 ## 5 -25 DL 461 N668DN LGA ATL 116 762 6 0 ## 6 12 UA 1696 N39463 EWR ORD 150 719 5 58 ## 7 19 B6 507 N516JB EWR FLL 158 1065 6 0 ## 8 -14 EV 5708 N829AS LGA IAD 53 229 6 0 ## 9 -8 B6 79 N593JB JFK MCO 140 944 6 0 ## 10 8 AA 301 N3ALAA LGA ORD 138 733 6 0 ## time_hour ## &lt;dttm&gt; ## 1 2013-01-01 05:00:00 ## 2 2013-01-01 05:00:00 ## 3 2013-01-01 05:00:00 ## 4 2013-01-01 05:00:00 ## 5 2013-01-01 06:00:00 ## 6 2013-01-01 05:00:00 ## 7 2013-01-01 06:00:00 ## 8 2013-01-01 06:00:00 ## 9 2013-01-01 06:00:00 ## 10 2013-01-01 06:00:00 ## # ... with 336,766 more rows # show up to 1000 rows and all columns flights %&gt;% View() # set option to see all columns and fewer rows options(dplyr.width = Inf, dplyr.print_min = 6) # reset options (or just close R) options(dplyr.width = NULL, dplyr.print_min = 10) 8.12 Resources Release announcements for version 0.3 and version 0.4 dplyr reference manual and vignettes Two-table vignette covering joins and set operations RStudios Data Wrangling Cheat Sheet for dplyr and tidyr dplyr GitHub repo and list of releases 8.13 Data School Blog Email newsletter YouTube channel "],["more-dplyr.html", "Chapter 9 More DPLYR 9.1 Introduction 9.2 Single table verbs 9.3 More with the pipe 9.4 Loading dplyr and the starwars dataset 9.5 starwars Excercises 9.6 nycflights13 Excercises 9.7 storms Excercises 9.8 starwars Excercises", " Chapter 9 More DPLYR 9.1 Introduction For more help PLEASE check out Introduction to dplyr introducing the key functionality of the dplyr package. Your life is about to change. For the better, even. 9.2 Single table verbs dplyr aims to provide a function for each basic verb of data manipulation. These verbs can be organised into three categories based on the component of the dataset that they work with: Rows: filter() chooses rows based on column values. slice() chooses rows based on location. arrange() changes the order of the rows. Columns: select() changes whether or not a column is included. rename() changes the name of columns. mutate() changes the values of columns and creates new columns. relocate() changes the order of the columns. Groups of rows: summarise() collapses a group into a single row. Itâs not that useful until we learn group_by() group_by() usually works with summarise() 9.3 More with the pipe All of the dplyr functions take a data frame (or tibble) as the first argument. Rather than forcing the user to either save intermediate objects or nest functions, dplyr provides the %&gt;% operator from magrittr. One step is then âpipedâ into the next step. You can use the pipe to rewrite multiple operations that you can read left-to-right, top-to-bottom (reading the pipe operator as âthenâ). What is this: %&gt;%? 9.4 Loading dplyr and the starwars dataset # You should already have done this but you&#39;ll need it install.packages(&quot;dplyr&quot;) library(dplyr) starwars %&gt;% filter(species == &quot;Droid&quot;) starwars %&gt;% select(name, ends_with(&quot;color&quot;)) starwars %&gt;% mutate(name, bmi = mass / ((height / 100) ^ 2)) %&gt;% select(name:mass, bmi) starwars %&gt;% arrange(desc(mass)) starwars %&gt;% group_by(species) %&gt;% summarise( n = n(), mass = mean(mass, na.rm = TRUE) ) %&gt;% filter( n &gt; 1, mass &gt; 50 ) 9.5 starwars Excercises Please use the starwars dataset from the dplyr package to answer the following questions: How may humans are in this dataset? How many characters are taller than 89 cm? How many characters are taller than 37 inches? How many characters are taller than 37 inches and weigh more than 55 pounds? How many characters are not human or droid? How many characters are not human or droid and are taller than 47 inches? Which species has the most individuals included in this data set? Which species has the tallest individuals on average? What is the tallest individual for each species? Calculate the BMI for each individual and determine which individual has the highest BMI. Use the formula bmi = mass/((height/100)^2) to calculate bmi. Which homeworld has the most individuals included in this data set? Which homeworld has the tallest individuals on average? What is the tallest individual for each eye color? #Comprehensive DPLYR Practice install.packages(&quot;nycflights13&quot;) 9.6 nycflights13 Excercises Using the nycflights13 package and the flights dataset use the dplyr package to answer these questions. Some answers are given in square brackets for you to check your answers. How many flights in Sept were late departing flights? [7815] How many flights in Sept were late departing flights that originated at JFK airport? [2649] How many flights in Sept were late departing flights with an origin of JFK airport and had an destination of anywhere except MIA? [2572] Which carrier had the most flights in this data set? [UA with 58665] Which destination had the most flights in this data set? [ORD with 17283] Which destination had the most flights with departure delays of greater than 60 minutes in this data set? [ORD with 1480] What was the longest arrival delay in this dataset? [1272] Which carrier in September had the most late departing flights? [UA with 1559] Create a variable called total.annoyance which arrival delay plus the departure delay for each flight. Which carrier with more than 10 flights in September had greatest % late departing flights? 9.7 storms Excercises Open the storms data from the dplyr package. Use ?storms to understand the data. Then answer: How many observations have both wind speeds of greater than 20 knots and air pressure of more 1010 millibars? How many observations have the storm name of Ana, Ernesto, Ophelia or Isidore? What is the average wind speed for each category of storm? For category 4 and 5 storms (combined) what is the average pressure? Create a variable called strength which is pressure divided by wind speed. What is the maximum strength in this data set? Which storm has the most observations? Which category 5 storm(s) have the greatest average wind speed? 9.8 starwars Excercises Please use the starwars dataset from the dplyr package to answer the following questions: Which species has the most individuals included in this data set? Which species has the tallest individuals on average? What is the tallest individual for each species? Calculate the BMI for each individual and determine which individual has the highest BMI. Use the formula bmi = mass/((height/100)^2) to calculate bmi. Which homeworld has the most individuals included in this data set? Which homeworld has the tallest individuals on average? What is the tallest individual for each eye color? "],["gdh-ice-cream.html", "Chapter 10 GDH Ice Cream 10.1 Problem Introduction 10.2 Assignment", " Chapter 10 GDH Ice Cream 10.1 Problem Introduction GDH provides ice cream for its wonderful customers. I LOVE GDH. Do you love it as much as me (lets discuss)? In the last three years GDH used ice cream, in pounds, by month, as shown in the attached file. ## Month.Name year1 year2 year3 ## Jan 60 67 64 ## Feb 68 67 72 ## Mar 83 62 61 ## Apr 102 95 107 ## May 95 105 101 ## Jun 57 89 75 ## Jul 61 57 81 ## Aug 109 109 104 ## Sep 56 86 88 ## Oct 53 53 65 ## Nov 74 72 72 ## Dec 73 64 65 10.2 Assignment Please answer the following questions using R:. GDH provides ice cream cones for its customers. In the last three years GDH used ice cream, in pounds, by month, as shown in the attached file. In R, create the above data frame and name it ice.cream What is another way you could have created the same data set? Using R, what is the mean using for the months of Feb and Oct? Create a chart showing ice cream use over time. Which year used the most ice cream? Which month has the highest standard deviation of ice cream use? Which year has the highest standard deviation of ice cream use? Also, you May want to check out this link to look at something called dataframes that may help with this assignment (but is not absolutely necessary) https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/data.frame Can you transpose your matrix? Can you add meaningful row names and column names? "],["linear-regression.html", "Chapter 11 Linear Regression 11.1 What is Machine Learning? 11.2 Model Structure 11.3 Interpretation of the Model 11.4 Applying the Model to Make Predictions 11.5 Review Questions", " Chapter 11 Linear Regression 11.1 What is Machine Learning? This is where the fun stuff begins! What we have learned up to this point has barely scratched the surface of what R is capable of. In the world of data science, R is used for three primary purposes, those purposes are (1) data transformation, (2) data wrangling, (3) machine learning. The other two purposes have been covered in earlier chapters of this book. The reason we covered the other topics first is that that lay the foundation. In the real world, it is likely you will never be given a clean data set, and you will have to do some wrangling and transformation before anything else is possible. After all, in the experience of many data science students, cleaning the data is the most tedious and time consuming process of a project. Enough of the old stuff, what is machine learning? According to the Merriam-Webster Dictionary, machine learning is the process by which a computer is able to improve its own performance by continuously incorporating new data into an existing statistical model. Lets take a trip back to the Target story discussed in the introductory chapter. The data scientist, or more likely data scientists (collaborative work is essential in this field), that worked on that model were likely experts in machine learning. They were able to train the computer to look through thousands (probably more) of customers data and the computer, based off the algorithms written by these data nerds, was able to predict whether a customer was pregnant! Think of other possible applications of this technology? We could predict how well a student will preform on an exam, the risk of someone suffering from a heart attack, or the likelihood that someone will default on a loan. Every field in existence today could find a way to implement machine learning to optimize their business. There are two branches of machine learning, supervised and unsupervised. Both have their own unique uses, however in this course we will focus on supervised machine learning. Supervised machine learning required us to provide a clean data set with clearly defined variables and instructions. Essentially, we give the computer the information it needs and provide it with specific instructions detailing what we would like to see happen, and it does the rest. Linear regression is typically the first method of supervised learning people are introduced to, and it will be the focus of this chapter. Note, these concepts are not all common sense and can be difficult to wrap your head around at times. Be sure to constantly turn to your instructor or peers for assistance and remember that there are hundreds of online resources at your disposal. As with anything though, practice makes perfect. The popular rule states that mastering a skill can take upwards of 10,000 hours! Now, this course is not going to take you 10 years to complete, however the goal is that by the end of this chapter you will know your way around the basics of linear regression. 11.2 Model Structure Lets look at a very simple model first. For this example, we will need to import the Introduction to Statistical Learning package (ISLR). We will use the credit data set that is part of the ISLR package. library(ISLR) data(&quot;Credit&quot;) attach(Credit) M1 &lt;- lm(Balance ~ Limit + Ethnicity) lm is the function we use to create linear regression models. Now, before we discuss interpreting the results we get from this function, we will discuss the different parts of the model. The ~ symbol is the key to this entire equation. We are telling R to predict whatever is on the left side of the tilde using the variables on the right. 11.3 Interpretation of the Model Lets run a summary on this model and see what we get. summary(M1) ## ## Call: ## lm(formula = Balance ~ Limit + Ethnicity) ## ## Residuals: ## Min 1Q Median 3Q Max ## -677.39 -145.75 -8.75 139.56 776.46 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3.078e+02 3.417e+01 -9.007 &lt;2e-16 *** ## Limit 1.718e-01 5.079e-03 33.831 &lt;2e-16 *** ## EthnicityAsian 2.835e+01 3.304e+01 0.858 0.391 ## EthnicityCaucasian 1.381e+01 2.878e+01 0.480 0.632 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 234 on 396 degrees of freedom ## Multiple R-squared: 0.743, Adjusted R-squared: 0.7411 ## F-statistic: 381.6 on 3 and 396 DF, p-value: &lt; 2.2e-16 There is a lot of statistical jargon included in our summary that may be unfamiliar to those who have not taken statistics before. That is okay, however, because we are going to breakdown the main statistics we are interested in. Lets start with our variables and their significance in the model. 11.3.1 P-Values The p-value of our model helps us either prove or disprove the null-hypothesis of our test. In the case of this class, the null-hypothesis is that there is no relationship between the variables we are using to make the predictions and the actual variable we are predicting. In other words, the smaller our p-value the higher the level of significance there is between our variables. When we run a summary of our linear regression model we are give multiple p-values. First, under coefficients, they are listed for each variable. This can help us optimize our model because we can see what variables are helping make the model more accurate versus those that may be hindering its performance. Also notice the asterisks next to our p-values. R kindly puts up to three stars next to each variable to help us visually tell if they are significant, essentially more stars means a lower p-value and thus a higher correlation. The second place we see a p-value is at the bottom of our summary. This p-value will give us the overall correlation that exists in our model. As we see in this case, our p-values for this model is &lt; .00000000000000022, that is a tiny number and frankly a great p-value. Typically we want our p-value to be .05 or smaller. A p-value of .05 tells us that we have a confidence level of 95%. 11.3.2 Multiple R-Squared R-squared tells us how well our model explains the variance in our variable. In other words, is the reason for the change in the independent variable actually due to our models prediction? The higher the r-squared, the more accurate our model is because the better the data fits it. The maximum value r-squared can be is 1. In our models case, we have a multiple r-squared of .743, this means our model is approximately 74.3% accurate as this is the amount of variance in the data caused by our dependent variable. Our r-squared could certainly be better. In fact, in the real world you typically are aiming for an r-squared above .9 or .95, which means you would have 90%-95% accuracy. 11.4 Applying the Model to Make Predictions This type of regression is refereed to as linear for a reason. If we were to visualize our model on a quadratic plane, we would see a line of best fit that would travel along through our data. This means we can simplify the model to fit the slope-intercept equation: y = m(x)+b In our case the slope of our line is related to the independent variables. The sum of these slopes will give us the overall slope of our line and the intercept is provided by the equation summary. If we modify this equation to be more applicable to our situation we would get something like this: y = m1x1 + m2x2  + b Lets look back at our example model from before M1 &lt;- lm(Balance ~ Limit + Ethnicity) summary(M1) ## ## Call: ## lm(formula = Balance ~ Limit + Ethnicity) ## ## Residuals: ## Min 1Q Median 3Q Max ## -677.39 -145.75 -8.75 139.56 776.46 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3.078e+02 3.417e+01 -9.007 &lt;2e-16 *** ## Limit 1.718e-01 5.079e-03 33.831 &lt;2e-16 *** ## EthnicityAsian 2.835e+01 3.304e+01 0.858 0.391 ## EthnicityCaucasian 1.381e+01 2.878e+01 0.480 0.632 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 234 on 396 degrees of freedom ## Multiple R-squared: 0.743, Adjusted R-squared: 0.7411 ## F-statistic: 381.6 on 3 and 396 DF, p-value: &lt; 2.2e-16 We see that our limit variable has an estimate of 1.718e-01, this is our slope. When dealing with quantitative variables, we simply multiply our slope by the intended independent variable. So, if we wanted to find the balance of someone with a limit of 400, we would multiply 1.718e-01 by 400. With the qualitative variables, in this case ethnicity, we multiply the estimate of the TRUE values by 1 and FALSE values by 0, thus cancelling the FALSE values out. Lets look at an example. If we used our above equation to predict the balance of someone who was Caucasian and has a credit limit of 500, here is the equation we would set up: y = (1.718e-1*500) + (1.381e+01*1) + (2.835e+01*0) + (-3.078e+02) y ## [1] -208.09 So, according to our model our customer would have a balance of -208.09. This number may seem funny, but keep in mind that our r-squared was not the best for this model making it inaccurate and the ethnicity of the customer was not highly correlated with the balance. Both of these facts may cause our prediction to be off. If we were actually creating a model that could predict balance, we would want to look at some of the more correlated variables in the data set. 11.5 Review Questions Create a linear model predicting using the ISLR data set that predicts a customers credit limit based on their age, current balance, and the number of cards they have. What is the p-value of this model? What does this tell us? List the variables in order from most correlated to least. How do you know that they are correlated? What is the multiple r-squared of the model? What does this tell us? Is this good or bad? What would be the credit limit of a 29 year old with 5 cards and a total balance of 1500? Explain what the following piece of code does library(ISLR) data(&quot;Credit&quot;) attach(Credit) q1 &lt;- lm(Cards ~ Limit + Balance + Education) "],["logistic-regression.html", "Chapter 12 Logistic Regression 12.1 Introduction 12.2 Training Data and Test Data 12.3 Model Structure 12.4 Model Interpretation 12.5 Review Questions", " Chapter 12 Logistic Regression 12.1 Introduction In the previous chapter we discussed linear regression, a type of supervised machine learning often used to make qualitative predictions. Now, we are moving on to logistic regression, another form of supervised machine learning that is commonly used for making predictions of some Boolean variable. This form of machine learning is typically used when using a prediction to answer a yes or no question. For instance, lets say we wanted to predict whether or not someone will suffer from a stroke. Using logistic regression, we can determine the probability that someone will either have a stroke (yes/true/positive result) or will not have a stroke (no/false/negative result). Also in this chapter we will discuss the difference between training and test data sets, why they are important, and how we apply them in logistic regression. This will help us to discuss the interpretation of these models and how we can test their accuracy. As stated previously, these topics may be difficult, and will be especially difficult if you still dont understand previous machine learning topics discussed in this course. Be sure to ask questions and seek help if you begin to struggle. This section will call on concepts from the very beginning of the course. 12.2 Training Data and Test Data In supervised machine learning, we provide the computer with data and in essence teach it how to treat the data and create predictions with it. Training data is the data we feed our model so that it can make accurate predictions of the probability of an outcome. Meanwhile, test data is the data we compare our model to in order to assess its accuracy. So, using the example above, if we were building a model to test the probability of someone having a stroke, we would segment our main data set into two parts, a training set and a test set. Then, after we build our model, we would compare the models output to the actual data and see how many times it made accurate predictions, this would in turn give us our models accuracy. 12.3 Model Structure Lets use the Auto data set to create a basic logistic regression model. Warning, we are going to be calling on information from earlier in the class a lot during these sections, so if you see any code you are unfamiliar with, first look in earlier class materials as it will not be reexplained here. Lets load in some data from the ISLR package and make some predictions using the mpg variable. We want to find the median of the variable, and then predict whether a vehicle will have an mpg above or below that middle point. To do this with logistic regression, we must create a factor object using mpg that our model will try to predict. library(ISLR) library(dplyr) data(&quot;Auto&quot;) attach(Auto) summary(Auto) ## mpg cylinders displacement horsepower weight ## Min. : 9.00 Min. :3.000 Min. : 68.0 Min. : 46.0 Min. :1613 ## 1st Qu.:17.00 1st Qu.:4.000 1st Qu.:105.0 1st Qu.: 75.0 1st Qu.:2225 ## Median :22.75 Median :4.000 Median :151.0 Median : 93.5 Median :2804 ## Mean :23.45 Mean :5.472 Mean :194.4 Mean :104.5 Mean :2978 ## 3rd Qu.:29.00 3rd Qu.:8.000 3rd Qu.:275.8 3rd Qu.:126.0 3rd Qu.:3615 ## Max. :46.60 Max. :8.000 Max. :455.0 Max. :230.0 Max. :5140 ## ## acceleration year origin name ## Min. : 8.00 Min. :70.00 Min. :1.000 amc matador : 5 ## 1st Qu.:13.78 1st Qu.:73.00 1st Qu.:1.000 ford pinto : 5 ## Median :15.50 Median :76.00 Median :1.000 toyota corolla : 5 ## Mean :15.54 Mean :75.98 Mean :1.577 amc gremlin : 4 ## 3rd Qu.:17.02 3rd Qu.:79.00 3rd Qu.:2.000 amc hornet : 4 ## Max. :24.80 Max. :82.00 Max. :3.000 chevrolet chevette: 4 ## (Other) :365 Auto &lt;- Auto %&gt;% mutate(mpg01 = ifelse(Auto$mpg &gt; 22.75, 1, 0)) Auto[Auto$mpg01 == 0,]$mpg01 &lt;- &quot;Below&quot; Auto[Auto$mpg01 == 1,]$mpg01 &lt;- &quot;Above&quot; Auto$mpg01 &lt;- as.factor(Auto$mpg01) attach(Auto) Now that we have a variable to predict, we can build the model. glm.auto &lt;- glm(mpg01 ~ weight + cylinders, data = Auto, family = &quot;binomial&quot;) As you can see, the structure is very similar to that of a linear regression model except for our specification of the data set we want it to use (this can be done in linear regression, but we did not earlier in the class) and the family argument which we have not seen before. In this course, we will only every specify family to be binomial, this tells R that the variable we are predicting only has two outcomes. The data argument is used to specify a training data set if we were using one, which we are not in this example. 12.4 Model Interpretation This is where things start to make a more complicated turn. We are going to look at how we evaluate the models performance. First, we must tell R to make the prediction and store the results in an object. mpg01.probs &lt;- predict(glm.auto, type = &#39;response&#39;) mpg01.probs[1:10] ## 1 2 3 4 5 6 7 8 ## 0.9769013 0.9866197 0.9719307 0.9716889 0.9729552 0.9979876 0.9980630 0.9978088 ## 9 10 ## 0.9984275 0.9915263 If we were to look at the mpg01.probs object it would contain the probability of the desired response, which is the true/positive response by default. However, we want this to be more intuitive, so we will make everything in the data set say Below unless the percentage is above what we consider a fair odds. So, in our case we will say that anything over 50% has a fair chance of being above the median mpg. mpg01.pred &lt;- rep(&#39;Below&#39;,392) mpg01.pred[mpg01.probs&gt;.5] = &#39;Above&#39; Finally, we can test our accuracy with a confusion matrix. The matrix will show our models predictions compared to the actual outcome. We can use this to test our accuracy and from there tweak different aspects of the model to help reduce variance. table(mpg01.pred,mpg01) ## mpg01 ## mpg01.pred Above Below ## Above 18 170 ## Below 178 26 Looking at the table we just produced, our accuracy is not the greatest. In fact, its pretty terrible. We get our accuracy by adding up the two areas where our model and the actual data match (in this case where above/above and below/below overlap) and then we divide this number by the total number of observations we had in the data set. Using our R arithmetic knowledge, we find our accuracy to be .1122 or 11.22%as stated before, a terrible accuracy. In fact, we typically aim for accuracy of 95% or better. However, having lower prediction accuracy is common and not necessarily a terrible thing. In fact, we sometimes learn more from inaccurate models than we do the more effective ones. For instance, we now know that perhaps our variables are not as correlated as we once thought, or perhaps we set the value for our mpg01.probs object too low. From here, the best thing to do is gather insights, tweak your model, and move on. 12.5 Review Questions What is the difference between logistic regression and linear regression? What is an example of an application for each of them? From scratch, create a logistic regression model using the Smarket data set from the ISLR package. You are to create a model predicting the direction variable. Test the accuracy of the model you created in the last question. Segment the Auto data set into training and test sets. The following code shows a logistic regression model using test and training data. Recreate a similar model using the Auto data set and the mpg variable. library(ISLR) data(&quot;Smarket&quot;) attach(Smarket) train=(Year&lt;2005) Smarket.2005=Smarket[!train,] Direction.2005=Direction[!train] glm.fits=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Smarket,family=binomial,subset=train) glm.probs=predict(glm.fits,Smarket.2005,type=&quot;response&quot;) glm.pred=rep(&quot;Down&quot;,252) glm.pred[glm.probs&gt;.5]=&quot;Up&quot; "],["dealing-with-errors.html", "Chapter 13 Dealing with Errors 13.1 Introduction 13.2 Troubleshooting Typical Errors", " Chapter 13 Dealing with Errors 13.1 Introduction So, you spent the last 2 hours tirelessly writing code for a project that is due tomorrow. You finally get to the very end, 100+ lines of hard work. You click run andyou get an error. Fortunately for you, you are not alone in this struggle, everyone battles with errors because unlike R, we are not experts at code syntax and we make mistakes. This short chapter will walk you through some techniques to help solve errors on your own and also provide some resources that may help you. Note: There are websites mentioned in this chapter that will help you solve errors in your code, and these solutions typically include the corrected code. You SHOULD NOT copy and paste code from the internet, rather you should learn how to fix your error and do the coding yourself. This is especially important because you will not be able to access internet resources during tests and quizzes in this course. 13.2 Troubleshooting Typical Errors This will not be a list of common errors you will face because there are hundreds, if not thousands, that could possibly occur. However, this section will tell you how to logically work through an error. Start by looking for a line number. Sometimes your error will include a line where the error is occurring, if it does you should go to that line and see if you can visually assess the problem. If it does not include a line number look for key words such as object names, functions, or anything else that may give you a hint as to where the error may be happening. Once you find the error, it is helpful if you have done similar work in a previous assignment because you can compare the code and see if it was simply an error with how you constructed a function. Also look for grammatical errors, capitalization errors, or even something small with punctuation like putting a comma instead of a period. If none of the above issues are present read through the error message in your console for hints. There is often fluff in error messages that is not very intuitive. Here is an example: It can be overwhelming at times when you get an error like this, especially if it is one you have never seen before. However, if you carefully read through you see it says x and y lengths differ All of those words just to say that wherever that error is located, the x and y axis are different lengths and therefor it will not run. So, when you face something like this, you just have to walk through it one word or line at a time and see if you can make sense of it. If nothing said up to this point has helped, do not fear. The resources listed below will help a ton! Take the time to explore the following websites BEFORE you encounter an error. Make accounts on all of them and save the home page to your favorites bar. It is almost guaranteed that you will need to visit at least one of these sites during the semester. They are links, so if you are viewing this electronically, simply click to navigate. Otherwise, copy and paste the resouce to Google and it will be the first link to show. StackOverflow GitHub RStudio Community R-Project Journal "],["data-analytics-i-quizzes.html", "Chapter 14 Data Analytics I Quizzes 14.1 Quiz One (Linear Regression) 14.2 Quiz Two 14.3 Quiz Three", " Chapter 14 Data Analytics I Quizzes 14.1 Quiz One (Linear Regression) Name: __________________________ Add a another variable (column) to the women dataframe called GPA which is these 15 numbers: 1.5, 3.7, 4,1, 3, 2.5, 3.8, 0.8, 2, 4, 1, 3, 2.5, 3.0, 4.0 Use GPA and weight to predict the height of a person who is 155 pounds and has a GPA if 3.33. What is your prediction? _______ Is GPA a significant predictor of height and how do you know? Create a figure showing a best fit line on of height and GPA. Install the dplyr package into your Rstudio session. 14.2 Quiz Two Name:___________________________________ ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 4 7 10 13 ## [2,] 2 5 8 11 14 ## [3,] 3 6 9 12 15 Write the code that creates this matrix: Write DIFFERENT code that creates this matrix in an alternate way: In the matrix above, what does [,4] mean? What code would return the value in the 3rd column and 3rd row? What single line of would give you the average of the all the numbers in columns 2, 4, and 5 and in rows 1 and 3? 14.3 Quiz Three Name: __________________________ df ## X1 X2 X3 X4 X5 X6 X7 X8 X9 X10 ## 1 1 11 21 31 41 51 61 71 81 91 ## 2 2 12 22 32 42 52 62 72 82 92 ## 3 3 13 23 33 43 53 63 73 83 93 ## 4 4 14 24 34 44 54 64 74 84 94 ## 5 5 15 25 35 45 55 65 75 85 95 ## 6 6 16 26 36 46 56 66 76 86 96 ## 7 7 17 27 37 47 57 67 77 87 97 ## 8 8 18 28 38 48 58 68 78 88 98 ## 9 9 19 29 39 49 59 69 79 89 99 ## 10 10 20 30 40 50 60 70 80 90 100 Consider the dataframe above called df. What would running this code return sum(df[7,7:10]) How can you tell if an object in R is a dataframe? How could you create the dataframe above called df? What code would return the average of row 2 of df? Consider mtcars dataset that comes preloaded with R that looks like this: head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 Why do I get this error when I run the code below: Error in plot(hp, mpg) : object 'hp' not found? plot(hp,mpg) Error in plot(hp, mpg) : object 'hp' not found Bonus: What is a topic that you find confusing at this point in class? "],["practice-final-exam.html", "Chapter 15 Practice Final Exam 15.1 100-Meter Freestyle Olympic Winning Time (seconds) 15.2 Starwars fun", " Chapter 15 Practice Final Exam 15.1 100-Meter Freestyle Olympic Winning Time (seconds) Create a table in R that looks like the data above. Call this table: swim ## year mens womens ## 1 1912 63.20 72.20 ## 2 1920 61.40 73.60 ## 3 1924 59.00 72.40 ## 4 1928 58.60 71.00 ## 5 1932 58.20 66.80 ## 6 1936 57.60 65.90 ## 7 1948 57.30 66.30 ## 8 1952 57.40 66.80 ## 9 1956 55.40 62.00 ## 10 1960 55.20 61.20 ## 11 1964 53.40 59.40 ## 12 1968 52.20 60.00 ## 13 1972 51.22 58.59 ## 14 1976 49.99 55.65 ## 15 1980 50.40 54.79 ## 16 1984 49.80 55.92 ## 17 1988 48.63 54.93 On 1 page, plot two graphs: a) year (x axis) vs Menâs time (y axis) and b) year (x axis) vs Womenâs time (y axis). Add a best fit line for menâs and womenâs winning times. Determine the womenâs time in 2016 according to the line of best fit based solely on the information provided by this best fit line (i.e, do NOT use a prediction function) and use R as a calculator obtain an estimate for the 2016 winning time. ## [1] 46.75584 Create a table based on swim that is comprised only of womenâs times for the years 1932 through 1972. Call this table swim2. Based on swim2, predict the winning womenâs times for 1976, 1980, 1984, and 1988. Feel free to use a predict function. ## fit lwr upr ## 1 57.30314 56.14272 58.46356 ## 2 56.24879 54.98460 57.51298 ## 3 55.19444 53.81969 56.56919 ## 4 54.14009 52.64950 55.63067 15.2 Starwars fun Use the starwars data in the dplyr package to answer the following questions: Body Mass Index (BMI) is defined as the body mass divided by the square of the body height. Use pounds and inches (convert given data as needed) and use this formula to cacluate BMI: Weight (lb) / [height (in)]2 x 703 ## # A tibble: 6 x 7 ## species mass height height.in height.in.squared mass.lbs bmi ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Hutt 1358 175 68.9 4747. 2994. 443. ## 2 Vulptereen 45 94 37.0 1370. 99.2 50.9 ## 3 Yoda&#39;s species 17 66 26.0 675. 37.5 39.0 ## 4 Human 120 178 70.1 4911. 265. 37.9 ## 5 Droid 140 200 78.7 6200. 309. 35.0 ## 6 Droid 32 96 37.8 1428. 70.5 34.7 How many of each species are on each homeworld? ## # A tibble: 58 x 3 ## species homeworld n ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Human Tatooine 8 ## 2 Human Naboo 5 ## 3 Human &lt;NA&gt; 5 ## 4 Droid &lt;NA&gt; 3 ## 5 Gungan Naboo 3 ## 6 Human Alderaan 3 ## 7 Droid Tatooine 2 ## 8 Human Corellia 2 ## 9 Human Coruscant 2 ## 10 Kaminoan Kamino 2 ## # ... with 48 more rows What homeworlds have the greatest % humans? ## # A tibble: 16 x 4 ## # Groups: homeworld [16] ## homeworld humans total.individuals pct.human ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Alderaan 3 3 1 ## 2 Corellia 2 2 1 ## 3 Stewjon 1 1 1 ## 4 Eriadu 1 1 1 ## 5 Bestine IV 1 1 1 ## 6 Socorro 1 1 1 ## 7 Bespin 1 1 1 ## 8 Chandrila 1 1 1 ## 9 Haruun Kal 1 1 1 ## 10 Serenno 1 1 1 ## 11 Concord Dawn 1 1 1 ## 12 Tatooine 8 10 0.8 ## 13 Coruscant 2 3 0.667 ## 14 &lt;NA&gt; 5 10 0.5 ## 15 Naboo 5 11 0.455 ## 16 Kamino 1 3 0.333 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
